---
layout: page
title: An AI Ethical Framework
---

{:.lead}
The six layers of a "generative AI" cake which meets our minimum threshold of moral and technical acceptability.
{:style="text-align:center"}


----

As [outlined by Whitefusion founder **Jared White** in Episode 111 of **Fresh Fusion Podcast**](https://jaredwhite.com/podcast/111/): 

1. **Generative AI tools must be 100% open.** The claims of keeping them closed for safety/security reasons are _bullshit_. If these tools are unsafe (and in many cases they are), they must be ==legally regulated==‚Äîjust like hard drugs, weapons, tobacco, child pornography, etc. Due to this requirement of openness, I basically reject all corporate operation of (and thus selling of) generative AI. Just like I ==don‚Äôt pay any corporation== to sell me the **Ruby programming language**, or the ability to **edit JPEG images**, or any number of other **vital programming and data manipulation tasks**, I don‚Äôt understand why I would pay a particular corporation for _access to generative AI_ (or even if it‚Äôs somehow free, only have that single corporate source for the technology).
2. **Generative AI tools must be completely transparent about the sources they use and why.** Black box algorithms are ==unacceptable==. Anyone claiming they don‚Äôt yet know how to make algorithms that aren‚Äôt black boxes are simply revealing these algorithms _can‚Äôt yet be used ethically_. I'm aware there's ongoing research to find ways to backtrack from monolithic outputs to the variety of inputs involved, but it's clear ==we'll need a whole lot more== of that baked in.
3. **The sources Generative AI tools use must be 100% opt-in.** There can‚Äôt be any of this ‚Äúwell, you should opt-out after the fact if you‚Äôre really worried about it‚Äù. ü§® All training datasets need to be ==100% vetted==, with all parties involved giving their _consent_ and receiving _reasonable compensation_ if indeed they wish to be compensated.
4. **Generative AI tools should be "narrowly" purposeful.** In other words, these general-purpose all-knowing, all-seeing, ==magical prompt machines== which can generate virtually any output you could imagine are _thoroughly unacceptable_. Tools which can provide endless ‚Äúnovel‚Äù output are tools which are ultimately **useless**. This isn‚Äôt anything like the reasoning capabilities of humans, or even the verified automation enabled by general-purpose computing. When it comes to AI algorithms, we need ==extremely targeted solutions== if we are to trust _anything_ coming out of them.
5. **Generative AI output should be tagged as AI-generated output, and it should be easy to trace how this output gets used throughout content pipelines.** The idea that you can just take giant reams of text, or still imagery, or video, and pass that off as human-made or compressively integrate it into something eventually human-made ==without any disclosure== and possibility of verification, is _thoroughly unacceptable_. AI output being promoted online without proper disclosure is **DESTROYING the fabric of the Open Web**. I am constantly second-guessing if the art I‚Äôm looking at is actually real or not, and _I‚Äôve been burned more than once_ (thinking I‚Äôm following an artist and then it turns out they‚Äôre just churning out regurgitated AI imagery). Blog posts featuring AI-generated imagery are simply awful‚Ä¶I almost always ==leave the article behind== and even unfollow people who do this habitually. _Don't do that!_ üòÖ
6. **Generative AI tools should be opt-in for users as well.** I ==reject all software== which adds generative AI to its feature set without the ability for me to opt-out, much less opt-in in the first place. Forcing me to have enabled access to these tools is _deeply offensive_. It‚Äôs even worse if it‚Äôs a job that‚Äôs requiring me to use these tools _as part of my job description_. That would be as bonkers to me as saying ==you can only work at this job== if you smoke, or drink alcohol, or carry a gun. That last one might make sense if, say, you're a police officer or in the military or _maybe_ in private security‚Äîbut otherwise **it‚Äôs thoroughly unacceptable**.
7. **I consider this seventh layer optional because there are ways to argue the point one direction or another**, but generative AI tools currently seem to take enormous resources in the sense of ==electricity usage==, semiconductor production requirements, etc. There‚Äôs a very real environmental cost here. I‚Äôm not actually sure how it compares to cryptocurrencies, which we already know are _horrendously bad_ for the environment‚Äîthis may be a bit less egregious, but ==it‚Äôs certainly not ideal==. Perhaps over time this issue will resolve itself to a degree as silicon technology improves, **but we‚Äôre not there yet.**

----

[Listen to the full **Fresh Fusion** episode](https://jaredwhite.com/podcast/111/) for a deep dive into this ethical approach to using generative AI tools and why virtually all tools in widespread use today fall wildly short in the morality department‚Äîwhich makes the embrace of these tools by corporations **incredibly disappointing**.

_Can we thread this needle?_

_==Is there a viable path forward?==_

<sl-button variant="primary" size="large" pill onclick="document.querySelector('sl-dialog').show()">Let‚Äôs Discuss!</sl-button>
